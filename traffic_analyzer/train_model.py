import argparse
import os
import sys
import time
import logging

import joblib
import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder

# === ÐŸÐ£Ð¢Ð˜ ===============================================================
BASE_DIR = os.path.dirname(__file__)
DATA_DIR = os.path.join(BASE_DIR, "data")
os.makedirs(DATA_DIR, exist_ok=True)

MODEL_PATH = os.path.join(DATA_DIR, "model.joblib")
DATASET_PATH = os.path.join(BASE_DIR, "..", "datasets", "merged_detailed.parquet")

log = logging.getLogger("IntelliSniff.train_model")


# === Ð—ÐÐ“Ð Ð£Ð—ÐšÐ ============================================================
def load_dataset(path=DATASET_PATH, label_type="binary"):
    """Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÑ‚ parquet Ð¸ Ð¿Ð¾Ð´Ð³Ð¾Ñ‚Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÑ‚ X, y"""
    print(f"ðŸ“‚ Loading dataset from {path}")
    df = pd.read_parquet(path)

    # Ð’Ñ‹Ð±Ð¾Ñ€ Ð¼ÐµÑ‚ÐºÐ¸
    if label_type == "multi" and "label_multi" in df.columns:
        y = df["label_multi"]
        y = LabelEncoder().fit_transform(y)
    elif "label_binary" in df.columns:
        y = df["label_binary"]
    elif "label" in df.columns:
        y = df["label"]
    else:
        raise ValueError("âŒ Dataset missing label column")

    # Ð’Ñ‹Ð±Ð¾Ñ€ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¾Ð²
    drop_cols = [c for c in ["label", "label_binary", "label_multi"] if c in df.columns]
    X = df.drop(columns=drop_cols, errors="ignore")

    # ÐŸÑ€ÐµÐ¾Ð±Ñ€Ð°Ð·Ð¾Ð²Ð°Ð½Ð¸Ðµ Ñ‚Ð¸Ð¿Ð¾Ð²
    X = X.select_dtypes(include=[np.number]).fillna(0).astype(np.float32)
    print(f"âœ… Dataset loaded: {X.shape[0]:,} rows, {X.shape[1]} features")
    return X, y


# === ÐžÐ‘Ð£Ð§Ð•ÐÐ˜Ð• ============================================================
def train_and_save(X, y, out_path=MODEL_PATH):
    """ÐžÐ±ÑƒÑ‡Ð°ÐµÑ‚ RandomForest Ð¸ ÑÐ¾Ñ…Ñ€Ð°Ð½ÑÐµÑ‚ Ð¼Ð¾Ð´ÐµÐ»ÑŒ"""
    # Ð£Ð´Ð°Ð»ÑÐµÐ¼ ÑÑ‚Ð°Ñ€ÑƒÑŽ Ð¼Ð¾Ð´ÐµÐ»ÑŒ, ÐµÑÐ»Ð¸ ÐµÑÑ‚ÑŒ
    if os.path.exists(out_path):
        try:
            os.remove(out_path)
            print(f"ðŸ§¹ Ð¡Ñ‚Ð°Ñ€Ñ‹Ð¹ Ñ„Ð°Ð¹Ð» Ð¼Ð¾Ð´ÐµÐ»Ð¸ ÑƒÐ´Ð°Ð»Ñ‘Ð½: {out_path}")
        except PermissionError:
            print(f"âš ï¸ ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ ÑƒÐ´Ð°Ð»Ð¸Ñ‚ÑŒ ÑÑ‚Ð°Ñ€ÑƒÑŽ Ð¼Ð¾Ð´ÐµÐ»ÑŒ (Ñ„Ð°Ð¹Ð» Ð·Ð°Ð½ÑÑ‚). Ð—Ð°ÐºÑ€Ð¾Ð¹ Ð¿Ñ€Ð¾Ñ†ÐµÑÑÑ‹ Ð¸ Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€Ð¸.")
            return None

    print("âš™ï¸  Splitting train/test...")
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y if len(set(y)) > 1 else None
    )

    print("ðŸŒ² Training RandomForestClassifier...")
    clf = RandomForestClassifier(
        n_estimators=200,
        max_depth=None,
        random_state=42,
        n_jobs=-1
    )
    clf.fit(X_train, y_train)
    y_pred = clf.predict(X_test)

    print("\nðŸ“Š [TRAIN REPORT]")
    print(classification_report(y_test, y_pred, zero_division=0))
    print(f"âœ… Accuracy: {accuracy_score(y_test, y_pred):.4f}")

    joblib.dump({
        "model": clf,
        "features": X.columns.tolist(),
        "trained_at": time.time(),
    }, out_path)

    print(f"ðŸ’¾ Model saved to: {out_path}")
    return out_path


# === ÐÐ’Ð¢Ðž-ÐŸÐ•Ð Ð•ÐžÐ‘Ð£Ð§Ð•ÐÐ˜Ð• ===================================================
def retrain_if_needed(force=False):
    """ÐŸÐµÑ€ÐµÐ¾Ð±ÑƒÑ‡Ð°ÐµÑ‚ Ð¼Ð¾Ð´ÐµÐ»ÑŒ, ÐµÑÐ»Ð¸ Ð´Ð°Ñ‚Ð°ÑÐµÑ‚ Ð¸Ð·Ð¼ÐµÐ½Ð¸Ð»ÑÑ"""
    if not os.path.exists(DATASET_PATH):
        print("âŒ Merged dataset not found:", DATASET_PATH)
        return None

    if not os.path.exists(MODEL_PATH):
        print("ðŸ“˜ No model found â€” training new one...")
        X, y = load_dataset()
        return train_and_save(X, y)

    model_mtime = os.path.getmtime(MODEL_PATH)
    data_mtime = os.path.getmtime(DATASET_PATH)
    if force or data_mtime > model_mtime:
        print("ðŸ” Dataset is newer â€” retraining model...")
        X, y = load_dataset()
        return train_and_save(X, y)

    print("âœ… Model is up-to-date.")
    return MODEL_PATH


def train_from_dataset(dataset_path=None, label_type="binary", out_path=MODEL_PATH):
    """Ð’Ñ‹ÑÐ¾ÐºÐ¾ÑƒÑ€Ð¾Ð²Ð½ÐµÐ²Ð°Ñ Ð¾Ð±Ñ‘Ñ€Ñ‚ÐºÐ°: Ð·Ð°Ð³Ñ€ÑƒÐ·Ð¸Ñ‚ÑŒ Ð´Ð°Ñ‚Ð°ÑÐµÑ‚ Ð¸ Ð¾Ð±ÑƒÑ‡Ð¸Ñ‚ÑŒ Ð¼Ð¾Ð´ÐµÐ»ÑŒ."""
    dataset_path = dataset_path or DATASET_PATH
    if not os.path.exists(dataset_path):
        raise FileNotFoundError(f"Dataset not found: {dataset_path}")
    X, y = load_dataset(path=dataset_path, label_type=label_type)
    return train_and_save(X, y, out_path=out_path)


def train_demo_model(out_path=MODEL_PATH):
    """ÐžÐ±ÑƒÑ‡Ð°ÐµÑ‚ ÑÐ¸Ð½Ñ‚ÐµÑ‚Ð¸Ñ‡ÐµÑÐºÑƒÑŽ Ð´ÐµÐ¼Ð¾-Ð¼Ð¾Ð´ÐµÐ»ÑŒ (Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ÑÑ Ð² UI)."""
    from .classification import train_demo_model as _train_demo_model

    return _train_demo_model(out_path)


def main(argv=None):
    """CLI-Ð²Ñ…Ð¾Ð´ Ð´Ð»Ñ python -m traffic_analyzer.train_model"""
    parser = argparse.ArgumentParser(description="Train IntelliSniff model")
    parser.add_argument(
        "--dataset",
        type=str,
        default=None,
        help="ÐŸÑƒÑ‚ÑŒ Ðº parquet/csv Ð´Ð°Ñ‚Ð°ÑÐµÑ‚Ñƒ (Ð¿Ð¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ datasets/merged_detailed.parquet)",
    )
    parser.add_argument(
        "--label-type",
        choices=["binary", "multi"],
        default="binary",
        help="Ð¢Ð¸Ð¿ Ð¼ÐµÑ‚Ð¾Ðº Ð´Ð»Ñ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ",
    )
    parser.add_argument(
        "--force",
        action="store_true",
        help="Ð˜Ð³Ð½Ð¾Ñ€Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÑƒ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð¸ Ð¼Ð¾Ð´Ð¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸Ð¸ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð¿Ñ€Ð¸ --retrain-if-needed",
    )
    parser.add_argument(
        "--retrain-if-needed",
        action="store_true",
        help="ÐŸÐµÑ€ÐµÐ¾Ð±ÑƒÑ‡Ð¸Ñ‚ÑŒ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ ÐµÑÐ»Ð¸ Ð´Ð°Ñ‚Ð°ÑÐµÑ‚ Ð½Ð¾Ð²ÐµÐµ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÑŽÑ‰ÐµÐ¹ Ð¼Ð¾Ð´ÐµÐ»Ð¸",
    )
    parser.add_argument(
        "--demo",
        action="store_true",
        help="ÐžÐ±ÑƒÑ‡Ð¸Ñ‚ÑŒ ÑÐ¸Ð½Ñ‚ÐµÑ‚Ð¸Ñ‡ÐµÑÐºÑƒÑŽ Ð´ÐµÐ¼Ð¾-Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð²Ð¼ÐµÑÑ‚Ð¾ Ñ€ÐµÐ°Ð»ÑŒÐ½Ð¾Ð³Ð¾ Ð´Ð°Ñ‚Ð°ÑÐµÑ‚Ð°",
    )
    args = parser.parse_args(argv)

    if args.demo:
        path = train_demo_model()
        print(f"âœ… Demo model saved to {path}")
        return path

    if args.retrain_if_needed:
        return retrain_if_needed(force=args.force)

    dataset_path = args.dataset or DATASET_PATH
    result = train_from_dataset(dataset_path, args.label_type)
    print(f"âœ… Model trained from {dataset_path} -> {result}")
    return result


# === MAIN ================================================================
if __name__ == "__main__":
    main(sys.argv[1:])
